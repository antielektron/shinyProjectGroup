\documentclass[runningheaders,a4paper]{llncs}

\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Darstellung von URLs
\usepackage{url}
\usepackage{amsmath,amssymb} 
\usepackage{listings}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{array}

% Benötigte Angaben für die Titelseite
\title{ Moment Shadow Mapping, Moment Based Volumetric Obscurance und Sample Distribution Shadow Maps }

\author{
	Akasha Jethwa 
	Matrikel-Nr: 2563201
	\and
	Jonas Weinz 
	Matrikel-Nr: 2571421
	\and
	Tom Kneiphof 
	Matrikel-Nr: 2662506
}

% Hier das Institut angeben
\institute{Institut für Informatik der Universität Bonn}

\begin{document}

% Erstellung des Titels
\maketitle

\begin{abstract}
Dieser Bericht ist Teil einer Projektgruppe am Institut für Informatik der Universität Bonn,
die sich mit der Implementierung drei verschiedener Echtzeit-Renderingtechniken für Schatten 
beschäftigt. In diesem Bericht wird die Funktionsweise und Implementierung von Sample Distribution Shadow Maps, 
Volumetric-Obscurance und Moment Shadow Mapping. Alle drei Techniken werden in einer eigenen Engine implementiert und
durch ein Demo-Spiel dargestellt.
\end{abstract}

\section{Einleitung}
Rendern von Schatten ist ein wichtiger Aspekt der interaktiven 3D Grafik. Die Struktur einer Szene, wirkt erst durch Schatten realisitisch und hilft dem Betrachter dabei, diese zu verstehen.
Allerdings ist das Berechnen der verschiedenen Schattentechniken auch aufwendig und oft anfällig für Fehlerartefakte. Deswegen untersuchen wir in diesem Paper 3 Techniken, welche verschiedene Lösungsansätze und Vorteile bieten. Zusätzlich implementieren wir alles in einer eigenen 3D Engine und generieren daraus ein kurzes Spiel um die Techniken zu demonstrieren.
\subsection{Sample Distribution Shadow Maps}
Hier könnte ein Text stehen
\subsection{Volumetric Obscurance}
Hier könnte ein Text stehen
\subsection{Moment Shadow Mapping}
Wir wollen eine Schattentechnik verwenden, die möglichst hohe Qualität liefert und dabei performant bleibt. Wünschenswert, wäre ebenfalls filterbare Shadow Maps und eine performante Methode. Moment Shadow Mapping liefert uns dieses Verfahren und wird im weiteren Verlauf erläutert und implementiert.

\section{Related Work}

TODO subsections or related work embeddet into techniques

Moment Shadow Mapping \cite{msm}, Variance Shadow Maps \cite{donnelly2006variance}, Percentage Closer Filtering \cite{reeves1987rendering}

Volumetric Obscurance \cite{loos2010volumetric}

Sample Distribution Shadow Maps \cite{lauritzen2011sample}

\section{Sample Distribution Shadow Maps}

Sample Distribution Shadow Maps (SDSMs) ist ein Verfahren zur adaptiven Optimierung der Shadow Map Auflösung unter Verwendung des Camera-Space Depth Buffers.

\subsection{Algorithmus}

% Cascaded Shadow Maps aka Z-Partitioning
SDSMs basieren auf Z-Partitoning, wobei das Kamera Frustum entlang der Blickrichtung in mehrere Teilfrusta partitioniert wird. Für jedes Teilfrustum wird eine eigene Shadow Map generiert.
Auf diese Weise kann mehr Shadow Map Auflösung für nahe Objekte verwendet werden, und weniger Auflösung für weit entfernte Objekte.

% Partitionierung
Für gute Ergebnisse ist eine geeignete Wahl der Partition ausschlaggebend.
Anstatt auf eine statische Partitionierung des Kamera Frustums zu setzen wird die Partitionierung von SDSMs in jedem Frame neu berechnet.

% - Min/Max Reduktion
% - Logarithmische Partitionierung
Zunächst wird die tatsächliche Near und Far Distanz der sichtbaren Geometrie im Kamera Frustums ermittelt. Dies geschieht mittels Min/Max Reduktion der Tiefenwerte im Kamera Depth Buffer.
Anschließend wird das Kamera Frustum zwischen tatsächlicher Near und Far Distanz logarithmisch partitioniert um das perspektivische Aliasing zu minimieren.

% Abgrenzung PSSM Logarithmic/Linear
PSSMs kennen die tatsächliche Near und Far Distanz nicht, und müssen mit der Near und Far Distanz der Projektionsmatrix arbeiten.
Eine logarithmische Partitionierung würde zu viel Shadow Map Auflösung in den sehr nahen Bereich verschieben, der oft leer ist.
PSSMs konvexkombinieren die Partitionsgrenzen der linearen und logarithmischen Partitionierung um mehr Auflösung von der Near Plane weg zu bewegen.
Optimale Koeffizienten müssen meist von Hand ermittelt werden.

% (K-Means and friends)
Weitere Möglichkeiten das Kamera Frustum intelligent zu partitionieren sind ein adaptiv logarithmisches und ein K-Means Verfahren.
Das adaptiv logarithmische Verfahren vermeidet Lücken im Histogramm des Kamera Depth Buffers, indem es die Partitionsgrenzen an das Ende von diesen schiebt.
Das K-Means Verfahren sucht zunächst Maxima im Histogramm des Kamera Depth Buffers und legt dann die Partition entsprechend um die gefundenen Maxima.
Für beide Verfahren muss zunächst ein Histogramm berechnet werden.


% Betrachte Punkte in Light-Space TODO
Der Algorithmus betrachtet die Verteilung aller sichtbaren Punkte der Szene aus der Sicht des Lichtes.
Hierzu wird für jedes Sample aus dem Kamera Depth Buffer die Position in der Welt rekonstruiert und in den Light Space transformiert.


% Tight Partition Frusta

% Andere Algorithmen benutzen Ecken von jedem Frustum um Shadow Map Frustum zu definieren
TODO



\subsection{Implementierung}

% Rendern der Shadow Map
Die Shadow Maps für die Kaskaden werden mittels Texture Arrays realisiert, wobei jede Kaskade einen eigenen Layer in dem Array erhält.
Beim Rendern der Shadow Map transformiert der Vertex Shader die Geometrie zunächst nur in das Welt Koordinatensystem und nicht direkt in das Frustum der Shadow Map.
Der Geometry Shader klont dann die Geometrie und transformiert sie für jede Kaskade mit der dazugehörigen Projektionsmatrix in das Shadow Map Frustum um sie in den entsprechenden Layer der Shadow Map zu rendern.
Anstatt die Near Plane des Shadow Map Frustums zu verschieben, um Geometrie die aus der Sicht des Lichtes vor dem Kamera Frustum liegt zu berücksichtigen, wird an der Near Plane des Shadow Map Frustums der Tiefenwert geclampt.

% Light Space (to detailed?)
% Um eine Transformation in den Light Space zu bekommen, der analog zum Camera Space die Szene aus der Sicht des Lichtes betrachtet, wird zunächst die Licht Richtung auf die Z Achse rotiert und anschließend die Z-Achse des Camera Spaces an der X-Achse ausgerichtet.

% Temporäre Licht Projektion
Um die Bounding Boxen der Geometrie in den einzelnen Kaskaden zu berechnen, müssen die Koordinaten im Light Space auf den Bereich $[0, 1]$ gemappt werden.
Hierzu werden die Eckpunkte im Screen Space in die Welt, und anschließend in den Light Space transformiert, wo dann deren Axis Aligned Bounding Box auf $[0, 1]^3$ projiziert wird.
So ist es garantiert, dass die Koordinaten sämmtlicher sichtbarer Geometrie im Light Space clamping in einer Textur gespeichert werden können.

% Reduktion 1 & 2
Die beiden Reduktionen werden jeweils in einem Compute Shader ausgeführt. Jeder Thread liest 1 bis 4 Einträge pro zu reduzierendem Wert ein. Jede Thread Gruppe (von 256 Threads) generiert einen neuen Eintrag pro Wert.
Ausserdem versuchen wir die Zugriffsmuster auf den Shared Memory so weit es geht zu optimieren und Bank Conflicts zu vermeiden \cite{reduction}.
Um so mehr verschiedene Werte auf einmal reduziert werden, um so mehr können idle Zeiten von Threads in den Thread Gruppen vermieden werden.
Anstatt dass nach einer halbierung der Daten die eine Hälfte der Threads ihre Arbeit beendigt, wird der erste zu reduzierende Wert von der ersten Hälfte der Threads, und die zweite zu reduzierende Variable von der zweiten Hälfte der Threads bearbeitet, und so weiter bis jeder Thread sich nur noch um höchstens einen Wert kümmern muss (z.B. Minimale X Koordinate der zweiten Kaskade).
Die Reduktionsergebnisse werden in 1D Texturen gespeichert, um die Anzahl der Threads die in einem Reduktionsschritt keine sinnvollen Daten einlesen zu minimieren.


% Keks


\paragraph{Erster Versuch}
Im ersten Ansatz haben wir die Reduktionen für die tatsächliche Near und Far Distanz sowie die Bounding Boxen der Geometrie in den Kaskaden auf der GPU berechnet.
Das Ergebnis haben wir auf die CPU zurück gelesen um aus den Near und Far Distanzen die Partition zu berechnen, bzw. aus den Bounding Boxen das Frustum für die entsprechende Shadow Map.
Um zu vermeiden, dass der CPU auf die GPU warten muss, haben wir die Ergebnisse aus dem vorherigen Frame, bzw. von vor zwei Frames genutzt, da deren Berechnung dann schon abgeschlossen sein sollte.
Um Bewegungen der Kamera zu kompensieren, haben wir die Ergebnisse aus dem Kamera Koordinatensystem des vergangenen Frames in die Welt transformiert und von dort in das aktuelle Kamera Koordinatensystem.
Was wir nicht kompensieren konnten, war das erscheinen neuer Geometrie, die durch die Bewegung der Kamera sichtbar wurde.
Das hat z.B. zu Bereichen zwischen den Kaskaden geführt, die nicht von einer Shadow Map abgedeckt wurden.

\paragraph{Zweiter Versuch}
Dieses Problem haben wir gelöst indem wir am Anfang jedes Frames einmal nur die Tiefe gerendert haben.
Anschließend haben wir darauf die Near und Far Distanz berechnet.
Anstatt auf die CPU zurück zu lesen, haben wir die Partition in einem Compute Shader auf der GPU berechnet.
Nachdem dann die Bounding Boxen der Kaskaden berechnet waren, haben wir daraus ebenfalls auf der GPU die Projektionsmatrizen für die Shadow Maps berechnet.

\section{Volumetric Obscurance}

	TODO
	
\section{Moment Shadow Mapping}

Um eine möglichst hohe Qualität an Schatten zu erreichen bieten sich verschiedene Verfahren an. Deswegen ist es wünschenswert für uns eine filterbare Shadow Map zu nutzen. Percentage Close Filtering eliminiert Aliasing Effekt durch samplen der Schadow Map und durch einen Filter Kernel.\cite{msm} 
Allerdings kann dies nur für einzelne Fragmente geschehen, da das Verfahren die Tiefenabhängig beim Schattentest nutzt.\cite{msm}
Es bietet sich daher an mit Momenten zu arbeiten. Variance Shadow Maps nutzen zwei Momente und bietet deshalb zusätzlich die quadrierte Tiefeninformation. Diese wird genutzt um PCF weiter zu approximieren und filterbare Shadow Maps zu nutzen.
Wir werden das Hamburger Moment Shadow Mapping nutzen, welches 4 Momente generiert und den Variance Shadow Maps ähnlich ist. Zum filtern nutzen wir MSAA und zum einen Gauss Filter. Die Implementierung war denkbar einfach, da wir bereits DirectX Shader Code hatten, durch die Präsentation des Moment Shadow Mapping Papers\cite{msm}. Diesen haben wir für OpenGL umgesetzt.

\subsection{Algorithmus}
%Füge Algorithmen 1-3 ein und beschreibe
Wir nutzen den Algorithmus Hamburger Moment Shadow Mapping. Dieser versucht das General Moment Problem\cite{msm} zu lösen. Hierfür nutzen wir Algorithmus 1. Hierfür nutzen wir die Algorithmus 3 aus dem Moment Shadow Mapping Paper. Der grundlegende Aufbau des MSM, ist dem des VSM sehr ähnlich, denn VSM ist hinsichtlich des MSM ein spezialfall für m = 2. Für uns wünschenswert, war aber eine Methode mit m = 4.
Algorithmus 1 minimiert Fs(zf), sodass wir eine untere Schranke nutzen können. Dies löst das General Moment Problem. Auch VSM löst dieses und der Vorteil liegt in der Vermeidung von Artefakten, wie etwa Surface acne. Übrig bleiben noch Artefakte wie wie Light Leeking durch falsche Schattenintensität, da wir bisher eine untere Schranke haben und die Werte niemals überschätzen. Eine weitere Vereinfachung in Richtung Hamburger MSM erreichen wir durch Algorithmus 2, welcher uns eine Linearkombination liefert um Fs(zf) zu minimieren. Desweiteren bestimmen wir Gewichte durch den Algorithmus 2 durch Es(b) = b und G(b,zf) = Fs(zf). Algorithmus 2 bietet aber noch nicht die nötige Robustheit für eine Echtzeitanwendung.\cite{msm}
Letztendlich führt uns dies zu Algorithmus 3. Dieser ist ein Spezialfall des Algorithmus 2 und liefert und letztendlich die Schattenintensität. Light Leeking und Aliasing werden elegant umgangen und wir erhalten eine Schattenintensität, die sowohl helle als auch dunkle Werte gut einschätzen kann. Ausserdem gilt dieser Algorithmus als robust genug für Echtzeitanwendung, was in der Implementierung aufgezeigt wird. Da Algorithmus 3 theoretisch auf double precision Werten aufbaut, welche zu Speicherintensiv wären, nutzt die Implementierung einen einfach Bias Moment Vector und im Paper wird gezeigt, das dies nicht zu besonders großen Fehlern führt. Weiterführend ist der Algorithmus im Paper Moment Shadow Mapping erklärt\cite{msm}
\subsection{Moment Based Volumetric Obscurance}
Für die Moment Based Volumetric Obscurance benötigen wir noch Gewichte aus dem Moment Shadow Mapping. Diese finden sich in Algorithmus 2 und werden in unserer Implementierung weiter genutzt.
Hierfür nutzen wir die Funktion Es(f) = Summe wi*f(zi) (Extra Paper!). Diese liefert uns den gewünschten Term für die Moment Based Volumetric Obscurance. Allerdings haben wir während der Implementierung noch kein stimmiges Bild erhalten, welches aber im Abschnitt der Implementierung weiter erläutert wird. Weiterführen wird der Algorithmus im Anhang erläutert, durch zusätzliche Notizen, welche wir für die Projekgruppe erhalten haben. Diese beziehen sich im speziellen auf die MBVO um Zusammenhang mit dem MSM. (CHRISTOPHS NOTIZEN EINFÜGEN)

\subsection{Implementierung}

Wir implementieren die Hamburger Moment Shadow Mapping Technik. 
Zuerst wird eine Moment Shadow Map gerendert. Der Unterschied zur normalen Shadow Map ist, das zusätzlich noch 4 Momente, bestehend aus der Tiefe der Shadow Map gespeichert werden. Diese reduntanten Tiefeninformationen können noch gefiltert werden. Wir verwenden hierfür einen Gauss Filter oder alternativ noch MSAA. Eine weitere Möglichkeit wäre Mip-Mapping. Da wir bereits eine Shadow Map rendern, müssen wir nur noch eine Funktion nutzen um die Momente zu generieren.
Im zweiten Schritt der Implementierung, wird ein gefiltertes Sample aus der Moment Shadow Map, sowie die Tiefe eines Shadow Map Fragments genutzt, um eine gefilterte Schatten Intensität zu erhalten. Dies wird durch den Algorithmus zwei aus dem Moment Shadow Mapping Paper erreicht.\cite{msm}
Wir nutzen hierfür eine weitere Funktion um diese Berechnungen durzuführen und einen Wert für die Schattenintensität zu generieren, welchen wir im Programm nutzen können. Dies ist im Abschnitt Algorithmus bereits näher erläutert.
Im Shader haben wir dann folgendes angewendet um oben genanntes umzusetzen.
Das erstellen der Momente passiert in einem eignen Shader. Hierfür nutzen wir die Tiefe und speichern uns zusätzlich noch die Tiefe hoch 2, 3 und 4. Diese werden gesampelt und dann weiter an den Fragment Shader gereicht.
Im Fragment Shader, verarbeiten wir die Momente. Das heißt wir benutzen zwei Funktion um oben genannte gefilterte Samples zu generieren und diese dann in einer in eine Schattenintensität umzuwandeln. Hierfür haben wir den gegeben Direct X Shader in OpenGL übersetzt. Beachtenswert war, das Matrixtransformationen etwas anders gehandhabt werden als in DirectX und ein paar Standardfunktionen selbstgeschrieben werden müssen, was in den ersten Versuchen zu Fehlern in den Momenten geführt hat.
\subsection{Moment Based Volumetric Obscurance}
Für das Moment Based Volumetric Obscurance benutzen wir die gleiche Herangehensweise. Allerdings hat es sich herausgestellt, dass die Transformation für 4 Momente zu Artefakten führt. Dies entspricht dem samplent im Fragment Shader aus der Implementierung des Moment Shadow Mapping. Deswegen wurde dieser Schritt für das Moment Based Volumetric Obscurance entfernt. Das samplen bei der Generierung der Momente bleibt erhalten. Problematisch ist hier die Varianz um einen möglichst korrekten Wert für die Vomuletric Obscurance zu erhalten. Möglicherweise sind hier noch weitere Feineinstellung und Variablen nötig um ein stimmiges Bild zu erhalten. Technisch gesehen, funktiert das Verfahren aber.
Wir wählen ebenfalls 4 Momente um die Volumetric Obscurance zu approximieren und berechnen die benötigten Gewichte durch eine Abbänderung der MSM Funktionen. Dies ist ebenfalls im Abschnitt Algorithmus näher erläutert.
Im Shader wird die Funktion zum generieren der Schattenintensität um eine Berechnung der Gewichte erweitert, sodass diese für die Volumetric Obscurance nutzbar ausgegeben werden können.
Die MBVO färbt Konturen der Geometrie sehr dunkel ein und hat Ähnlichkeiten mit enem Cell Shading Effekt.



\section{Fazit}


\subsection{SDSM}	
% Verbesserung der MSM durch SDSM
% TODO erstmal nur skizziert!
SDSMs optimieren nicht nur die Ausnutzung der Shadow Map Auflösung, sondern auch die Ausnutzung der zur Verfügung stehenden Genauigkeit in der Shadow Map, da die Shadow Map Frusta in allen drei Dimensionen eng um die sichtbare Geometrie gelegt wird.
Dies kommt dem Moment Shadow Mapping zu gute, da so feinere Abstufungen in den Momenten erlaubt werden können.


\subsection{Moment Shadow Mapping}
Das Moment Shadow Mapping bietet uns Schatten mit hoher Qualität, welche auch sehr gut zur Geltung kommen. Artefakte wie Aliasing und Light Leeking werden optimal gemindert bzw. ganz eliminiert. Ausserdem funktiort die Implementierung sehr einfach. Das Verfahren ist schnell und bietet beim filtern viele Freiheiten. Wir nutzen Gauss und 1xMSAA-16xMSAA welches verschiedene Ergebnisse liefert.
Auch dies hat sich kaum auf die Performance ausgewirkt und wir sind mit dem Ergebniss sehr zufrieden.
\subsection{Moment Based Volumetric Obscurance}
Das Verfahren zur Moment Based Volumetric Obscurance war ebenfalls leicht umzusetzen, da sich die Implementierung kaum vom MSM unterscheidet. Aufgrund von anfänglichen Artefakten, haben wir aber eine sample Methode entfernt, welches ein stimmigeres Bild ergab. Insgesamt ist das Bild aber noch nicht stimmig genug, hier müssen wir weiter mit den Werten experimentieren, damit keine Cell Shading Optik erscheint. Interessant ist das Moment Based Volumetric Obscurance aber ebenfalls für grossflächuiges Filtern, welches noch weitere Experimente benötigt.
>>>>>>> weitere Updates zu MSM und MBSO tex
% Literaturverzeichnis:
\bibliography{lit}
\bibliographystyle{alpha}

\end{document}

